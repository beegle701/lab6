---
title: "lab6"
subtitle: "Ecosystem Science and Sustainability 330"
author: 
  - name: Nick Beegle
    email: beegle99@colostate.edu
format: html
execute: 
  echo: true
---

```{r}
library(tidyverse)
library(tidymodels)
library(powerjoin)
library(glue)
library(vip)
library(baguette)
```

```{r}
root  <- 'https://gdex.ucar.edu/dataset/camels/file'
download.file('https://gdex.ucar.edu/dataset/camels/file/camels_attributes_v2.0.pdf','data/camels_attributes_v2.0.pdf')

types <- c("clim", "geol", "soil", "topo", "vege", "hydro")
# Where the files live online ...
remote_files  <- glue('{root}/camels_{types}.txt')
# where we want to download the data ...
local_files   <- glue('data/camels_{types}.txt')
# data download
walk2(remote_files, local_files, download.file, quiet = TRUE)
#read and murge data
camels <- map(local_files, read_delim, show_col_types = FALSE)
```

```{r}
camels <- power_full_join(camels ,by = 'gauge_id')
```

## Question 1

Q: What does zero_q_freq represent?

zero_q_freq shows the frequency of when q=0 inmillimeters per day as a percentage.

```{r}
ggplot(data = camels, aes(x = gauge_lon, y = gauge_lat)) +
  borders("state", colour = "blue") +
  geom_point(aes(color = q_mean)) +
  scale_color_gradient(low = "red", high = "green") +
  ggthemes::theme_map()
```

## Question 2

```{r}
p1 <- ggplot(data = camels, aes(x = gauge_lon, y = gauge_lat)) +
  borders("state", colour = "blue") +
  geom_point(aes(color = aridity)) +
  scale_color_gradient(low = "red", high = "green") +
  labs(title = "Aridity of Sites") +
  ggthemes::theme_map()

p2 <- ggplot(data = camels, aes(x = gauge_lon, y = gauge_lat)) +
  borders("state", colour = "blue") +
  geom_point(aes(color = p_mean)) +
  scale_color_gradient(low = "red", high = "green") +
  ggthemes::theme_map() + 
  labs(title = "P Mean of Sites")
library(patchwork)
print(p1 | p2)

```

```{r}
camels |> 
  select(aridity, p_mean, q_mean) |> 
  drop_na() |> 
  cor()
```

```{r}
# Create a scatter plot of aridity vs rainfall
ggplot(camels, aes(x = aridity, y = p_mean)) +
  # Add points colored by mean flow
  geom_point(aes(color = q_mean)) +
  # Add a linear regression line
  geom_smooth(method = "lm", color = "red", linetype = 2) +
  # Apply the viridis color scale
  scale_color_viridis_c() +
  # Add a title, axis labels, and theme (w/ legend on the bottom)
  theme_linedraw() + 
  theme(legend.position = "bottom") + 
  labs(title = "Aridity vs Rainfall vs Runnoff", 
       x = "Aridity", 
       y = "Rainfall",
       color = "Mean Flow")
```

```{r}
ggplot(camels, aes(x = aridity, y = p_mean)) +
  geom_point(aes(color = q_mean)) +
  geom_smooth(method = "lm") +
  scale_color_viridis_c() +
  # Apply log transformations to the x and y axes
  scale_x_log10() + 
  scale_y_log10() +
  theme_linedraw() +
  theme(legend.position = "bottom") + 
  labs(title = "Aridity vs Rainfall vs Runnoff", 
       x = "Aridity", 
       y = "Rainfall",
       color = "Mean Flow")
```

```{r}
ggplot(camels, aes(x = aridity, y = p_mean)) +
  geom_point(aes(color = q_mean)) +
  geom_smooth(method = "lm") +
  # Apply a log transformation to the color scale
  scale_color_viridis_c(trans = "log") +
  scale_x_log10() + 
  scale_y_log10() +
  theme_linedraw() +
  theme(legend.position = "bottom",
        # Expand the legend width ...
        legend.key.width = unit(2.5, "cm"),
        legend.key.height = unit(.5, "cm")) + 
  labs(title = "Aridity vs Rainfall vs Runnoff", 
       x = "Aridity", 
       y = "Rainfall",
       color = "Mean Flow") 
```

```{r}
set.seed(123)

camels <- camels |> 
  mutate(logQmean = log(q_mean))


camels_split <- initial_split(camels, prop = 0.8)
camels_train <- training(camels_split)
camels_test  <- testing(camels_split)

camels_cv <- vfold_cv(camels_train, v = 10)
```

```{r}

rec <-  recipe(logQmean ~ aridity + p_mean, data = camels_train) %>%
  step_log(all_predictors()) %>%
  step_interact(terms = ~ aridity:p_mean) |> 
  step_naomit(all_predictors(), all_outcomes())
```

```{r}

baked_data <- prep(rec, camels_train) |> 
  bake(new_data = NULL)

lm_base <- lm(logQmean ~ aridity * p_mean, data = baked_data)
summary(lm_base)
```

```{r}
summary(lm(logQmean ~ aridity + p_mean + aridity_x_p_mean, data = baked_data))
```

```{r}
test_data <-  bake(prep(rec), new_data = camels_test)
test_data$lm_pred <- predict(lm_base, newdata = test_data)
```

```{r}
metrics(test_data, truth = logQmean, estimate = lm_pred)
```

```{r}
ggplot(test_data, aes(x = logQmean, y = lm_pred, colour = aridity)) +
  # Apply a gradient color scale
  scale_color_gradient2(low = "red", mid = "blue", high = "green") +
  geom_point() +
  geom_abline(linetype = 2) +
  theme_linedraw() + 
  labs(title = "Linear Model: Observed vs Predicted",
       x = "Observed Log Mean Flow",
       y = "Predicted Log Mean Flow",
       color = "Aridity")
```

```{r}
# Define model
lm_model <- linear_reg() %>%
  # define the engine
  set_engine("lm") %>%
  # define the mode
  set_mode("regression")

# Instantiate a workflow ...
lm_wf <- workflow() %>%
  # Add the recipe
  add_recipe(rec) %>%
  # Add the model
  add_model(lm_model) %>%
  # Fit the model to the training data
  fit(data = camels_train) 

# Extract the model coefficients from the workflow
summary(extract_fit_engine(lm_wf))$coefficients
```

```{r}
summary(lm_base)$coefficients
```

```{r}

lm_data <- augment(lm_wf, new_data = camels_test)
dim(lm_data)
```

```{r}
metrics(lm_data, truth = logQmean, estimate = .pred)

ggplot(lm_data, aes(x = logQmean, y = .pred, colour = aridity)) +
  scale_color_viridis_c() +
  geom_point() +
  geom_abline() +
  theme_linedraw()
```

```{r}
library(baguette)
library(ranger)
rf_model <- rand_forest() %>%
  set_engine("ranger", importance = "impurity") %>%
  set_mode("regression")

rf_wf <- workflow() %>%
  # Add the recipe
  add_recipe(rec) %>%
  # Add the model
  add_model(rf_model) %>%
  # Fit the model
  fit(data = camels_train) 
```

```{r}
rf_data <- augment(rf_wf, new_data = camels_test)
dim(rf_data)
```

```{r}
metrics(rf_data, truth = logQmean, estimate = .pred)

ggplot(rf_data, aes(x = logQmean, y = .pred, colour = aridity)) +
  scale_color_viridis_c() +
  geom_point() +
  geom_abline() +
  theme_linedraw()
```

```{r}
wf <- workflow_set(list(rec), list(lm_model, rf_model)) %>%
  workflow_map('fit_resamples', resamples = camels_cv) 

autoplot(wf)
```

```{r}
rank_results(wf, rank_metric = "rsq", select_best = TRUE)
```

## Question 3

```{r}
xgb_model <- boost_tree() %>%
  set_engine("xgboost") %>%
  set_mode("regression")

nn_model <- bag_mlp() %>%
  set_engine("nnet") %>%
  set_mode("regression")

```

```{r}
library(xgboost)
wf <- workflow_set(list(rec), list(lm_model, rf_model, xgb_model, nn_model)) %>%
  workflow_map('fit_resamples', resamples = camels_cv) 

autoplot(wf)
```

```{r}
rank_results(wf, rank_metric = "rsq", select_best = TRUE)
```

Q: Which of the 4 models would you move forward with?

The model with the highest r-squared test value should be the best fit. In this case it is a neural network.

## Question 4

**Data Splitting**

```{r}
set.seed(123)

camels1 <- camels |> 
  mutate(logQmean = log(q_mean))

camels_split <- initial_split(camels1, prop = 0.75)
camels_train <- training(camels_split)
camels_test  <- testing(camels_split)

camels_cv <- vfold_cv(camels_train, v = 10)

```

**Recipe**

```{r}

rec1 <-  recipe(logQmean ~ aridity + p_mean + soil_porosity, data = camels_train) %>%
  step_log(all_predictors()) %>%
  step_interact(terms = ~ aridity:p_mean) %>%  
  step_naomit(all_predictors(), all_outcomes())


baked_data <- prep(rec1, camels_train) |> 
  bake(new_data = NULL)

lm_base1 <- lm(logQmean ~ ., data = baked_data)
summary(lm_base1)

```

Q: Why are you choosing this formula?

I am choosing soil porosity for my model's predictor because there is a direct effect on discharge. I believe the higher the porosity the less discharge as the soil will retain more moisture. The lower the porosity the higher the discharge will be as the water can more easily run off the soil.

**Define 3 Models**

```{r}
rf_mod <- rand_forest() %>% 
  set_engine('ranger') %>% 
  set_mode("regression")

b_mod <- boost_tree() %>% 
  set_engine('xgboost') %>% 
  set_mode("regression")

nn_mod <- mlp(hidden = 10) %>% 
  set_engine('nnet') %>% 
  set_mode("regression")
```

**Workflow set**

```{r}
wf1 <- workflow_set(list(rec1), list(
                                   rf_mod,
                                   b_mod,
                                   nn_mod)) %>% 
  workflow_map(resamples = camels_cv)

```

Q: What model works the best and why?

The random forest model has the highest r-squared value and lowest root mean squared error so it looks like the most accurate.

```{r}
autoplot(wf1) 

ranked_results <- rank_results(wf1, rank_metric = "rsq",
               select_best = TRUE)
print(ranked_results)
```

**Extract and Evaluate**

```{r}
rf_wf1 <- workflow() %>%
  add_recipe(rec1) %>%
  add_model(rf_mod) %>%
  fit(data = camels_train) 


rf_data <- augment(rf_wf1, new_data = camels_test)
dim(rf_data)

ggplot(rf_data, aes(x = logQmean, y = .pred, colour = aridity)) +
  scale_color_gradient(low = "red", high = "green") +
  geom_point() +
  geom_abline() +
  theme_linedraw()

```

Q: What do you think of the results?

I think that the model is working well. The points are mostly around the line of best fit with few outliers probably due to prediction errors. In general the model seems to accuratley capture the relationship.
